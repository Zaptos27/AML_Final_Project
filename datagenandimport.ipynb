{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import numpy as np\n",
    "import os\n",
    "import soundfile as sf\n",
    "from scipy.signal import stft\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from multiprocessing import Pool\n",
    "# If you have a GPU, put the data on the GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "directory = \"../Data/slakh2100_flac_redux/train\"\n",
    "listdir = os.listdir(directory)\n",
    "listdir.sort()\n",
    "format = '.flac'\n",
    "savedir = 'data/train'\n",
    "sample_freq = 44100\n",
    "freq_amount = 129\n",
    "mixing = True\n",
    "mix_amount = 2\n",
    "np.random.seed(0)\n",
    "\n",
    "\n",
    "def load_sound(file_path):\n",
    "    data, _ = sf.read(file_path)\n",
    "    return data\n",
    "\n",
    "\n",
    "def parallel_load(file_path):\n",
    "    num_processes = 8\n",
    "    with Pool(num_processes) as pool:\n",
    "        data = pool.map(load_sound, file_path)\n",
    "\n",
    "    return np.sum(data ,axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 252.00 MiB (GPU 0; 9.77 GiB total capacity; 2.45 GiB already allocated; 132.06 MiB free; 2.46 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m get_ipython()\u001b[39m.\u001b[39;49mrun_cell_magic(\u001b[39m'\u001b[39;49m\u001b[39mtimeit\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mwhile True:\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m    tr = np.random.choice(listdir)\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m    tr_dicts_2 = \u001b[39;49m\u001b[39m{}\u001b[39;49;00m\u001b[39m\\n\u001b[39;49;00m\u001b[39m    tr_dict = \u001b[39;49m\u001b[39m{}\u001b[39;49;00m\u001b[39m\\n\u001b[39;49;00m\u001b[39m    tr_path = os.path.join(directory, tr)\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m    with open(os.path.join(tr_path, \u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mmetadata.yaml\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m)) as meta:\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m        metadata = yaml.safe_load(meta)\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m\\n\u001b[39;49;00m\u001b[39m    file_inst = np.array([[stem + format, metadata[\u001b[39;49m\u001b[39m\\'\u001b[39;49;00m\u001b[39mstems\u001b[39;49m\u001b[39m\\'\u001b[39;49;00m\u001b[39m][stem][\u001b[39;49m\u001b[39m\\'\u001b[39;49;00m\u001b[39minst_class\u001b[39;49m\u001b[39m\\'\u001b[39;49;00m\u001b[39m]] for stem in metadata[\u001b[39;49m\u001b[39m\\'\u001b[39;49;00m\u001b[39mstems\u001b[39;49m\u001b[39m\\'\u001b[39;49;00m\u001b[39m].keys()])\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m\\n\u001b[39;49;00m\u001b[39m    stems_path = os.path.join(tr_path, \u001b[39;49m\u001b[39m\\'\u001b[39;49;00m\u001b[39mstems\u001b[39;49m\u001b[39m\\'\u001b[39;49;00m\u001b[39m)\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m    file_inst = file_inst[[file_inst[:,0][i] in os.listdir(stems_path) for i in range(len(file_inst))]]\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m    # combine all stems from the same instrument and track using soundfile\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m    for inst in np.unique(file_inst[:,1]):\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m        inst_files = file_inst[file_inst[:,1] == inst][:,0]\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m        inst_files = [os.path.join(stems_path, inst_file) for inst_file in inst_files]\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m\\n\u001b[39;49;00m\u001b[39m        inst_data = parallel_load(inst_files)\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m        #inst_data = np.array([sf.read(inst_file)[0] for inst_file in inst_files])\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m        #inst_data = np.sum(inst_data, axis=0)\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m\\n\u001b[39;49;00m\u001b[39m        tr_dict.update(\u001b[39;49m\u001b[39m{\u001b[39;49m\u001b[39minst: inst_data})\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m\\n\u001b[39;49;00m\u001b[39m    # Choose a random amount of instruments to combine (between 2 and lenght-1)\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m    if mixing:\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m        # Find all instruments that are in the dictionary\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m        inst_in_dict = list(tr_dict.keys())\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m        for _ in range(mix_amount):\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m            # Choose the instruments to combine\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m            inst_amount = np.random.randint(2, len(inst_in_dict))\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m            inst_to_mix = np.random.choice(inst_in_dict, inst_amount, replace=False)\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m            # Add the combined data to the dictionary\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m            tr_dict.update(\u001b[39;49m\u001b[39m{\u001b[39;49m\u001b[39m\\'\u001b[39;49;00m\u001b[39m\\'\u001b[39;49;00m\u001b[39m.join(inst_to_mix):  np.sum([tr_dict[inst] for inst in inst_to_mix], axis=0)})\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m\\n\u001b[39;49;00m\u001b[39m     # Add mix to the dictionary\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m    inst_data = np.array([sf.read(os.path.join(tr_path, \u001b[39;49m\u001b[39m\\'\u001b[39;49;00m\u001b[39mmix\u001b[39;49m\u001b[39m\\'\u001b[39;49;00m\u001b[39m + format))[0]])\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m    tr_dict.update(\u001b[39;49m\u001b[39m{\u001b[39;49m\u001b[39m\\'\u001b[39;49;00m\u001b[39mmix\u001b[39;49m\u001b[39m\\'\u001b[39;49;00m\u001b[39m: inst_data})\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m\\n\u001b[39;49;00m\u001b[39m    for inst in tr_dict.keys():\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m        # compute the STFT of the combined data\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m        f, t, Zxx = stft(tr_dict[inst], fs=sample_freq, nperseg=freq_amount*2-2)\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m        tr_dicts_2.update(\u001b[39;49m\u001b[39m{\u001b[39;49m\u001b[39minst: torch.view_as_real_copy(torch.from_numpy(Zxx).to(torch.complex128).to(device))})\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m    torch.cuda.empty_cache()\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m    break\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py:2475\u001b[0m, in \u001b[0;36mInteractiveShell.run_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2473\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuiltin_trap:\n\u001b[1;32m   2474\u001b[0m     args \u001b[39m=\u001b[39m (magic_arg_s, cell)\n\u001b[0;32m-> 2475\u001b[0m     result \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   2477\u001b[0m \u001b[39m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[1;32m   2478\u001b[0m \u001b[39m# when using magics with decodator @output_can_be_silenced\u001b[39;00m\n\u001b[1;32m   2479\u001b[0m \u001b[39m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[1;32m   2480\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(fn, magic\u001b[39m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[39mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/IPython/core/magics/execution.py:1174\u001b[0m, in \u001b[0;36mExecutionMagics.timeit\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1171\u001b[0m         \u001b[39mif\u001b[39;00m time_number \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0.2\u001b[39m:\n\u001b[1;32m   1172\u001b[0m             \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m-> 1174\u001b[0m all_runs \u001b[39m=\u001b[39m timer\u001b[39m.\u001b[39;49mrepeat(repeat, number)\n\u001b[1;32m   1175\u001b[0m best \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m(all_runs) \u001b[39m/\u001b[39m number\n\u001b[1;32m   1176\u001b[0m worst \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(all_runs) \u001b[39m/\u001b[39m number\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/timeit.py:206\u001b[0m, in \u001b[0;36mTimer.repeat\u001b[0;34m(self, repeat, number)\u001b[0m\n\u001b[1;32m    204\u001b[0m r \u001b[39m=\u001b[39m []\n\u001b[1;32m    205\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(repeat):\n\u001b[0;32m--> 206\u001b[0m     t \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeit(number)\n\u001b[1;32m    207\u001b[0m     r\u001b[39m.\u001b[39mappend(t)\n\u001b[1;32m    208\u001b[0m \u001b[39mreturn\u001b[39;00m r\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/IPython/core/magics/execution.py:158\u001b[0m, in \u001b[0;36mTimer.timeit\u001b[0;34m(self, number)\u001b[0m\n\u001b[1;32m    156\u001b[0m gc\u001b[39m.\u001b[39mdisable()\n\u001b[1;32m    157\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 158\u001b[0m     timing \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minner(it, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimer)\n\u001b[1;32m    159\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    160\u001b[0m     \u001b[39mif\u001b[39;00m gcold:\n",
      "File \u001b[0;32m<magic-timeit>:42\u001b[0m, in \u001b[0;36minner\u001b[0;34m(_it, _timer)\u001b[0m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 252.00 MiB (GPU 0; 9.77 GiB total capacity; 2.45 GiB already allocated; 132.06 MiB free; 2.46 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "while True:\n",
    "    tr = np.random.choice(listdir)\n",
    "    tr_dicts_2 = {}\n",
    "    tr_dict = {}\n",
    "    tr_path = os.path.join(directory, tr)\n",
    "    with open(os.path.join(tr_path, \"metadata.yaml\")) as meta:\n",
    "        metadata = yaml.safe_load(meta)\n",
    "\n",
    "    file_inst = np.array([[stem + format, metadata['stems'][stem]['inst_class']] for stem in metadata['stems'].keys()])\n",
    "\n",
    "    stems_path = os.path.join(tr_path, 'stems')\n",
    "    file_inst = file_inst[[file_inst[:,0][i] in os.listdir(stems_path) for i in range(len(file_inst))]]\n",
    "    # combine all stems from the same instrument and track using soundfile\n",
    "    for inst in np.unique(file_inst[:,1]):\n",
    "        inst_files = file_inst[file_inst[:,1] == inst][:,0]\n",
    "        inst_files = [os.path.join(stems_path, inst_file) for inst_file in inst_files]\n",
    "\n",
    "        inst_data = parallel_load(inst_files)\n",
    "        #inst_data = np.array([sf.read(inst_file)[0] for inst_file in inst_files])\n",
    "        #inst_data = np.sum(inst_data, axis=0)\n",
    "\n",
    "        tr_dict.update({inst: inst_data})\n",
    "\n",
    "    # Choose a random amount of instruments to combine (between 2 and lenght-1)\n",
    "    if mixing:\n",
    "        # Find all instruments that are in the dictionary\n",
    "        inst_in_dict = list(tr_dict.keys())\n",
    "        for _ in range(mix_amount):\n",
    "            # Choose the instruments to combine\n",
    "            inst_amount = np.random.randint(2, len(inst_in_dict))\n",
    "            inst_to_mix = np.random.choice(inst_in_dict, inst_amount, replace=False)\n",
    "            # Add the combined data to the dictionary\n",
    "            tr_dict.update({''.join(inst_to_mix):  np.sum([tr_dict[inst] for inst in inst_to_mix], axis=0)})\n",
    "\n",
    "     # Add mix to the dictionary\n",
    "    inst_data = np.array([sf.read(os.path.join(tr_path, 'mix' + format))[0]])\n",
    "    tr_dict.update({'mix': inst_data})\n",
    "\n",
    "    for inst in tr_dict.keys():\n",
    "        # compute the STFT of the combined data\n",
    "        f, t, Zxx = stft(tr_dict[inst], fs=sample_freq, nperseg=freq_amount*2-2)\n",
    "        tr_dicts_2.update({inst: torch.view_as_real_copy(torch.from_numpy(Zxx).to(torch.complex128).to(device))})\n",
    "    torch.cuda.empty_cache()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
