{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "from IPython.display import Audio\n",
    "\n",
    "import soundfile\n",
    "import soundfile as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.fc1 = nn.Linear(16 * 16, 120) # 16*5*5 input, 120 output\n",
    "        self.fc2 = nn.Linear(120, 84) # 120 input, 84 output\n",
    "        self.fc3 = nn.Linear(84, 16 * 16) # 84 input, 10 output\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.flatten(1) # flatten all dimensions except batch dimension\n",
    "        x = F.relu(self.fc1(x)) # 400 -> 120\n",
    "        x = F.relu(self.fc2(x)) # 120 -> 84\n",
    "        x = self.fc3(x) # 84 -> 10\n",
    "        x = x.view(-1, 16, 16) # reshape to 4D tensor\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self,C,L):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.bn1 = nn.BatchNorm2d(6)\n",
    "        self.conv2 = nn.Conv2d(6, 18, 5)\n",
    "        self.bn2 = nn.BatchNorm2d(18)\n",
    "        self.conv3 = nn.Conv2d(18, 32, 5)\n",
    "        self.bn3 = nn.BatchNorm2d(32)\n",
    "        self.fc1 = nn.Linear(32 * 9 * 84, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 16)\n",
    "        self.fc4 = nn.Linear(16, 4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n",
    "        print(x.shape)\n",
    "        print(x.flatten().shape)\n",
    "        x = x.view(-1, 32 * 9 * 84)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 100, 700])"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(1,1,100, (2*C+1)*L).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 32, 9, 84])\n",
      "torch.Size([24192])\n",
      "Epoch [1/5], Loss: 1.027587652206421\n",
      "torch.Size([1, 32, 9, 84])\n",
      "torch.Size([24192])\n",
      "Epoch [2/5], Loss: 2.238055944442749\n",
      "torch.Size([1, 32, 9, 84])\n",
      "torch.Size([24192])\n",
      "Epoch [3/5], Loss: 1.1282685995101929\n",
      "torch.Size([1, 32, 9, 84])\n",
      "torch.Size([24192])\n",
      "Epoch [4/5], Loss: 1.3727883100509644\n",
      "torch.Size([1, 32, 9, 84])\n",
      "torch.Size([24192])\n",
      "Epoch [5/5], Loss: 1.269115924835205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([100, 100])) that is different to the input size (torch.Size([1, 100])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "C = 3\n",
    "L = 100\n",
    "model = CNN(C=3,L=100)\n",
    "\n",
    "input = torch.randn(1,1,100, (2*C+1)*L)\n",
    "\n",
    "target = torch.randn(100, L)\n",
    "\n",
    "torch.seed = 0\n",
    "\n",
    "\n",
    "# Training loop\n",
    "num_epochs =5\n",
    "# Define your loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Set the model in training mode\n",
    "    model.train()\n",
    "\n",
    "    # Forward pass\n",
    "    output = model(input)\n",
    "\n",
    "    # Calculate the loss\n",
    "    loss = criterion(output, target)\n",
    "\n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Print the loss for monitoring\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item()}\")\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), \"trained_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This can be used when we want to overlay multiple trained models\n",
    "class prepModel(nn.Module):\n",
    "    def __init__(self, input_shape):\n",
    "        super(prepModel, self).__init__()\n",
    "        self.mfcc_model = prepareMfccModel(input_shape) #\n",
    "        self.bass_model = prepareBassModel()\n",
    "        self.guitar_model = prepareGuitarModel()\n",
    "        self.piano_model = preparePianoModel()\n",
    "        self.drums_model = prepareDrumsModel()\n",
    "\n",
    "    def forward(self, x):\n",
    "        mfcc = self.mfcc_model(x)\n",
    "        bass_output = self.bass_model(mfcc)\n",
    "        guitar_output = self.guitar_model(mfcc)\n",
    "        piano_output = self.piano_model(mfcc)\n",
    "        drums_output = self.drums_model(mfcc)\n",
    "        concat_output = torch.cat([bass_output, guitar_output, piano_output, drums_output], dim=1)\n",
    "        return concat_output\n",
    "    \n",
    "class prepareBassModel(CNN):\n",
    "    def __init__(self):\n",
    "        super(prepareBassModel, self).__init__()\n",
    "\n",
    "class prepareGuitarModel(CNN):\n",
    "    def __init__(self):\n",
    "        super(prepareGuitarModel, self).__init__()\n",
    "\n",
    "class preparePianoModel(CNN):\n",
    "    def __init__(self):\n",
    "        super(preparePianoModel, self).__init__()\n",
    "\n",
    "class prepareDrumsModel(CNN):\n",
    "    def __init__(self):\n",
    "        super(prepareDrumsModel, self).__init__()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class torchAgent:\n",
    "    def __init__(self,model, loss_fn, data_path: str = None, valid_path: str = path, optimizer = None, device: str = None, epoch: int = 0, model_path = None, verbose: int = 2, track_amount: int = None, **kwargs):\n",
    "        # device: cpu / gpu\n",
    "        if device is None:\n",
    "            self.device = torch.device(\n",
    "                \"cuda\" if torch.cuda.is_available() else \"cpu\" # set device\n",
    "            )\n",
    "        else:\n",
    "            self.device = device # set device\n",
    "        self.model = model.to(self.device) # set model\n",
    "        self.loss_fn = loss_fn # set loss function\n",
    "        self.optimizer = optimizer # set optimizer\n",
    "        self.scheduler = None # set scheduler\n",
    "        self.epoch = epoch # set epoch\n",
    "        self.verbose = verbose # set verbose\n",
    "        if model_path is None:\n",
    "            self.model_path = f'model_{datetime.now().strftime(\"%y_%m_%d_%H%M\")}' # set model path\n",
    "        else:\n",
    "            self.model_path = model_path\n",
    "\n",
    "        if data_path is not None:\n",
    "            self.data_path  = 'data' #data path\n",
    "        else:\n",
    "            self.data_path = data_path\n",
    "\n",
    "        if valid_path is None:\n",
    "            self.valid_path = 'data' #validataion path\n",
    "        else:\n",
    "            self.valid_path = valid_path\n",
    "\n",
    "        if track_amount is None:\n",
    "            self.track_amount = len(os.listdir(self.data_path))\n",
    "        else:\n",
    "            self.track_amount = track_amount\n",
    "\n",
    "    \n",
    "    def add_loss_fn(self, loss_fn):\n",
    "        self.loss_fn = loss_fn\n",
    "\n",
    "    def add_optimizer(self, optimizer, **kwargs):\n",
    "        self.optimizer = optimizer(self.model.parameters(), **kwargs)\n",
    "\n",
    "    def add_scheduler(self, scheduler, **kwargs):\n",
    "        self.scheduler = scheduler(self.optimizer, **kwargs)\n",
    "\n",
    "    def load_data(self, path: str):\n",
    "        data = torch.Tensor(np.random.rand(100, 16, 16)).to(self.device)\n",
    "        labels = torch.Tensor(np.random.rand(100, 16, 16)).to(self.device)\n",
    "\n",
    "        return data, labels\n",
    "\n",
    "    def tracks(self, validate: bool = False):\n",
    "        if validate:\n",
    "            self.data_path = self.valid_path\n",
    "        #find all tracks in data path folder\n",
    "        for track in os.listdir(self.data_path):\n",
    "            yield self.load_data(track)\n",
    "\n",
    "    def train_one_epoch(self, **kwargs):\n",
    "        self.model.train(True)\n",
    "        running_loss = 0.\n",
    "\n",
    "        for i, (data, labels) in enumerate(self.tracks()):\n",
    "            # Zero your gradients for every batch!\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            # calculate loss\n",
    "            loss = self.loss_fn(self.model(data), labels)\n",
    "\n",
    "            # backpropagation\n",
    "            loss.backward()\n",
    "\n",
    "            # update parameters\n",
    "            self.optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            print(f'Batch: [{i+1}] loss: {loss.item():.3f}, loss: {running_loss:.3f}',end='\\r')\n",
    "\n",
    "            # free memory\n",
    "            del data, labels, loss\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        self.model.train(False)\n",
    "        return running_loss/self.track_amount\n",
    "    \n",
    "    def validate(self, **kwargs):\n",
    "        self.model.train(False)\n",
    "        running_loss = 0.\n",
    "\n",
    "        for i, (data, labels) in enumerate(self.tracks(validate=True)):\n",
    "            # calculate loss\n",
    "            loss = self.loss_fn(self.model(data), labels)\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            print(f'\\nBatch: [{i+1}] Loss: {loss.item():.3f}, Total loss: {running_loss:.3f}',end='\\n')\n",
    "\n",
    "            # free memory\n",
    "            del data, labels, loss\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        return running_loss/self.track_amount\n",
    "\n",
    "    def train(self, **kwargs):\n",
    "        best_loss = np.inf\n",
    "        for epoch in range(self.epoch):\n",
    "            print(f'Epoch: [{epoch+1}/{self.epoch}]')\n",
    "            epoch_loss = self.train_one_epoch(**kwargs)\n",
    "            print(f'Epoch: [{epoch+1}/{self.epoch}] loss: {epoch_loss:.3f}')\n",
    "            valid_loss = self.validate(**kwargs)\n",
    "            if best_loss > valid_loss:\n",
    "                print('Saving model...')\n",
    "                self.save_model()\n",
    "                best_loss = valid_loss\n",
    "            if self.scheduler is not None:\n",
    "                self.scheduler.step()\n",
    "        print('Finished Training')\n",
    "\n",
    "    def save_model(self):\n",
    "        torch.save(self.model.state_dict(), self.model_path)\n",
    "        print(f'Model saved at {self.model_path}')\n",
    "\n",
    "    def load_model(self, model_path: str):\n",
    "        self.model.load_state_dict(torch.load(model_path))\n",
    "        print(f'Model loaded from {model_path}')        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/10]\n",
      "Epoch: [1/10] loss: 0.331oss: 2.978\n",
      "\n",
      "Batch: [1] Loss: 0.333, Total loss: 0.333\n",
      "\n",
      "Batch: [2] Loss: 0.334, Total loss: 0.667\n",
      "\n",
      "Batch: [3] Loss: 0.329, Total loss: 0.996\n",
      "\n",
      "Batch: [4] Loss: 0.331, Total loss: 1.327\n",
      "\n",
      "Batch: [5] Loss: 0.334, Total loss: 1.661\n",
      "\n",
      "Batch: [6] Loss: 0.329, Total loss: 1.990\n",
      "\n",
      "Batch: [7] Loss: 0.329, Total loss: 2.320\n",
      "\n",
      "Batch: [8] Loss: 0.330, Total loss: 2.650\n",
      "\n",
      "Batch: [9] Loss: 0.330, Total loss: 2.980\n",
      "\n",
      "Batch: [10] Loss: 0.329, Total loss: 3.309\n",
      "\n",
      "Batch: [11] Loss: 0.333, Total loss: 3.642\n",
      "\n",
      "Batch: [12] Loss: 0.331, Total loss: 3.973\n",
      "\n",
      "Batch: [13] Loss: 0.333, Total loss: 4.307\n",
      "\n",
      "Batch: [14] Loss: 0.332, Total loss: 4.638\n",
      "\n",
      "Batch: [15] Loss: 0.332, Total loss: 4.971\n",
      "\n",
      "Batch: [16] Loss: 0.330, Total loss: 5.301\n",
      "\n",
      "Batch: [17] Loss: 0.337, Total loss: 5.638\n",
      "\n",
      "Batch: [18] Loss: 0.332, Total loss: 5.970\n",
      "\n",
      "Batch: [19] Loss: 0.328, Total loss: 6.298\n",
      "\n",
      "Batch: [20] Loss: 0.334, Total loss: 6.631\n",
      "\n",
      "Batch: [21] Loss: 0.330, Total loss: 6.961\n",
      "Saving model...\n",
      "Model saved at model_23_06_06_1059\n",
      "Epoch: [2/10]\n",
      "Epoch: [2/10] loss: 0.771loss: 6.941\n",
      "\n",
      "Batch: [1] Loss: 0.328, Total loss: 0.328\n",
      "\n",
      "Batch: [2] Loss: 0.330, Total loss: 0.659\n",
      "\n",
      "Batch: [3] Loss: 0.330, Total loss: 0.989\n",
      "\n",
      "Batch: [4] Loss: 0.329, Total loss: 1.318\n",
      "\n",
      "Batch: [5] Loss: 0.330, Total loss: 1.648\n",
      "\n",
      "Batch: [6] Loss: 0.333, Total loss: 1.981\n",
      "\n",
      "Batch: [7] Loss: 0.331, Total loss: 2.312\n",
      "\n",
      "Batch: [8] Loss: 0.332, Total loss: 2.644\n",
      "\n",
      "Batch: [9] Loss: 0.329, Total loss: 2.973\n",
      "\n",
      "Batch: [10] Loss: 0.330, Total loss: 3.303\n",
      "\n",
      "Batch: [11] Loss: 0.333, Total loss: 3.635\n",
      "\n",
      "Batch: [12] Loss: 0.330, Total loss: 3.966\n",
      "\n",
      "Batch: [13] Loss: 0.328, Total loss: 4.294\n",
      "\n",
      "Batch: [14] Loss: 0.331, Total loss: 4.624\n",
      "\n",
      "Batch: [15] Loss: 0.328, Total loss: 4.952\n",
      "\n",
      "Batch: [16] Loss: 0.328, Total loss: 5.281\n",
      "\n",
      "Batch: [17] Loss: 0.328, Total loss: 5.609\n",
      "\n",
      "Batch: [18] Loss: 0.330, Total loss: 5.939\n",
      "\n",
      "Batch: [19] Loss: 0.327, Total loss: 6.266\n",
      "\n",
      "Batch: [20] Loss: 0.332, Total loss: 6.597\n",
      "\n",
      "Batch: [21] Loss: 0.330, Total loss: 6.927\n",
      "Saving model...\n",
      "Model saved at model_23_06_06_1059\n",
      "Epoch: [3/10]\n",
      "Epoch: [3/10] loss: 0.765loss: 6.884\n",
      "\n",
      "Batch: [1] Loss: 0.324, Total loss: 0.324\n",
      "\n",
      "Batch: [2] Loss: 0.326, Total loss: 0.650\n",
      "\n",
      "Batch: [3] Loss: 0.327, Total loss: 0.978\n",
      "\n",
      "Batch: [4] Loss: 0.330, Total loss: 1.308\n",
      "\n",
      "Batch: [5] Loss: 0.329, Total loss: 1.636\n",
      "\n",
      "Batch: [6] Loss: 0.325, Total loss: 1.961\n",
      "\n",
      "Batch: [7] Loss: 0.325, Total loss: 2.286\n",
      "\n",
      "Batch: [8] Loss: 0.327, Total loss: 2.613\n",
      "\n",
      "Batch: [9] Loss: 0.326, Total loss: 2.939\n",
      "\n",
      "Batch: [10] Loss: 0.326, Total loss: 3.265\n",
      "\n",
      "Batch: [11] Loss: 0.326, Total loss: 3.591\n",
      "\n",
      "Batch: [12] Loss: 0.327, Total loss: 3.918\n",
      "\n",
      "Batch: [13] Loss: 0.328, Total loss: 4.246\n",
      "\n",
      "Batch: [14] Loss: 0.326, Total loss: 4.572\n",
      "\n",
      "Batch: [15] Loss: 0.324, Total loss: 4.896\n",
      "\n",
      "Batch: [16] Loss: 0.326, Total loss: 5.221\n",
      "\n",
      "Batch: [17] Loss: 0.324, Total loss: 5.546\n",
      "\n",
      "Batch: [18] Loss: 0.331, Total loss: 5.877\n",
      "\n",
      "Batch: [19] Loss: 0.326, Total loss: 6.203\n",
      "\n",
      "Batch: [20] Loss: 0.328, Total loss: 6.531\n",
      "\n",
      "Batch: [21] Loss: 0.328, Total loss: 6.859\n",
      "Saving model...\n",
      "Model saved at model_23_06_06_1059\n",
      "Epoch: [4/10]\n",
      "Epoch: [4/10] loss: 0.761loss: 6.850\n",
      "\n",
      "Batch: [1] Loss: 0.324, Total loss: 0.324\n",
      "\n",
      "Batch: [2] Loss: 0.327, Total loss: 0.651\n",
      "\n",
      "Batch: [3] Loss: 0.327, Total loss: 0.978\n",
      "\n",
      "Batch: [4] Loss: 0.326, Total loss: 1.304\n",
      "\n",
      "Batch: [5] Loss: 0.325, Total loss: 1.629\n",
      "\n",
      "Batch: [6] Loss: 0.326, Total loss: 1.955\n",
      "\n",
      "Batch: [7] Loss: 0.325, Total loss: 2.280\n",
      "\n",
      "Batch: [8] Loss: 0.327, Total loss: 2.607\n",
      "\n",
      "Batch: [9] Loss: 0.326, Total loss: 2.933\n",
      "\n",
      "Batch: [10] Loss: 0.327, Total loss: 3.259\n",
      "\n",
      "Batch: [11] Loss: 0.324, Total loss: 3.584\n",
      "\n",
      "Batch: [12] Loss: 0.323, Total loss: 3.906\n",
      "\n",
      "Batch: [13] Loss: 0.324, Total loss: 4.230\n",
      "\n",
      "Batch: [14] Loss: 0.323, Total loss: 4.554\n",
      "\n",
      "Batch: [15] Loss: 0.327, Total loss: 4.881\n",
      "\n",
      "Batch: [16] Loss: 0.322, Total loss: 5.202\n",
      "\n",
      "Batch: [17] Loss: 0.324, Total loss: 5.526\n",
      "\n",
      "Batch: [18] Loss: 0.324, Total loss: 5.850\n",
      "\n",
      "Batch: [19] Loss: 0.324, Total loss: 6.175\n",
      "\n",
      "Batch: [20] Loss: 0.327, Total loss: 6.502\n",
      "\n",
      "Batch: [21] Loss: 0.322, Total loss: 6.824\n",
      "Saving model...\n",
      "Model saved at model_23_06_06_1059\n",
      "Epoch: [5/10]\n",
      "Epoch: [5/10] loss: 0.756loss: 6.803\n",
      "\n",
      "Batch: [1] Loss: 0.322, Total loss: 0.322\n",
      "\n",
      "Batch: [2] Loss: 0.324, Total loss: 0.646\n",
      "\n",
      "Batch: [3] Loss: 0.323, Total loss: 0.969\n",
      "\n",
      "Batch: [4] Loss: 0.324, Total loss: 1.292\n",
      "\n",
      "Batch: [5] Loss: 0.324, Total loss: 1.617\n",
      "\n",
      "Batch: [6] Loss: 0.322, Total loss: 1.939\n",
      "\n",
      "Batch: [7] Loss: 0.322, Total loss: 2.261\n",
      "\n",
      "Batch: [8] Loss: 0.323, Total loss: 2.585\n",
      "\n",
      "Batch: [9] Loss: 0.324, Total loss: 2.909\n",
      "\n",
      "Batch: [10] Loss: 0.321, Total loss: 3.230\n",
      "\n",
      "Batch: [11] Loss: 0.322, Total loss: 3.552\n",
      "\n",
      "Batch: [12] Loss: 0.322, Total loss: 3.874\n",
      "\n",
      "Batch: [13] Loss: 0.322, Total loss: 4.196\n",
      "\n",
      "Batch: [14] Loss: 0.324, Total loss: 4.521\n",
      "\n",
      "Batch: [15] Loss: 0.322, Total loss: 4.842\n",
      "\n",
      "Batch: [16] Loss: 0.325, Total loss: 5.167\n",
      "\n",
      "Batch: [17] Loss: 0.326, Total loss: 5.493\n",
      "\n",
      "Batch: [18] Loss: 0.321, Total loss: 5.814\n",
      "\n",
      "Batch: [19] Loss: 0.327, Total loss: 6.141\n",
      "\n",
      "Batch: [20] Loss: 0.326, Total loss: 6.467\n",
      "\n",
      "Batch: [21] Loss: 0.323, Total loss: 6.790\n",
      "Saving model...\n",
      "Model saved at model_23_06_06_1059\n",
      "Epoch: [6/10]\n",
      "Epoch: [6/10] loss: 0.753loss: 6.774\n",
      "\n",
      "Batch: [1] Loss: 0.325, Total loss: 0.325\n",
      "\n",
      "Batch: [2] Loss: 0.324, Total loss: 0.649\n",
      "\n",
      "Batch: [3] Loss: 0.320, Total loss: 0.970\n",
      "\n",
      "Batch: [4] Loss: 0.325, Total loss: 1.294\n",
      "\n",
      "Batch: [5] Loss: 0.323, Total loss: 1.618\n",
      "\n",
      "Batch: [6] Loss: 0.322, Total loss: 1.940\n",
      "\n",
      "Batch: [7] Loss: 0.321, Total loss: 2.261\n",
      "\n",
      "Batch: [8] Loss: 0.323, Total loss: 2.584\n",
      "\n",
      "Batch: [9] Loss: 0.318, Total loss: 2.902\n",
      "\n",
      "Batch: [10] Loss: 0.322, Total loss: 3.224\n",
      "\n",
      "Batch: [11] Loss: 0.321, Total loss: 3.545\n",
      "\n",
      "Batch: [12] Loss: 0.321, Total loss: 3.867\n",
      "\n",
      "Batch: [13] Loss: 0.324, Total loss: 4.191\n",
      "\n",
      "Batch: [14] Loss: 0.322, Total loss: 4.513\n",
      "\n",
      "Batch: [15] Loss: 0.321, Total loss: 4.834\n",
      "\n",
      "Batch: [16] Loss: 0.322, Total loss: 5.156\n",
      "\n",
      "Batch: [17] Loss: 0.320, Total loss: 5.476\n",
      "\n",
      "Batch: [18] Loss: 0.325, Total loss: 5.801\n",
      "\n",
      "Batch: [19] Loss: 0.322, Total loss: 6.124\n",
      "\n",
      "Batch: [20] Loss: 0.322, Total loss: 6.446\n",
      "\n",
      "Batch: [21] Loss: 0.321, Total loss: 6.766\n",
      "Saving model...\n",
      "Model saved at model_23_06_06_1059\n",
      "Epoch: [7/10]\n",
      "Epoch: [7/10] loss: 0.754loss: 6.785\n",
      "\n",
      "Batch: [1] Loss: 0.322, Total loss: 0.322\n",
      "\n",
      "Batch: [2] Loss: 0.321, Total loss: 0.643\n",
      "\n",
      "Batch: [3] Loss: 0.322, Total loss: 0.966\n",
      "\n",
      "Batch: [4] Loss: 0.324, Total loss: 1.289\n",
      "\n",
      "Batch: [5] Loss: 0.323, Total loss: 1.612\n",
      "\n",
      "Batch: [6] Loss: 0.325, Total loss: 1.938\n",
      "\n",
      "Batch: [7] Loss: 0.322, Total loss: 2.259\n",
      "\n",
      "Batch: [8] Loss: 0.324, Total loss: 2.583\n",
      "\n",
      "Batch: [9] Loss: 0.323, Total loss: 2.906\n",
      "\n",
      "Batch: [10] Loss: 0.325, Total loss: 3.231\n",
      "\n",
      "Batch: [11] Loss: 0.324, Total loss: 3.555\n",
      "\n",
      "Batch: [12] Loss: 0.321, Total loss: 3.876\n",
      "\n",
      "Batch: [13] Loss: 0.322, Total loss: 4.198\n",
      "\n",
      "Batch: [14] Loss: 0.320, Total loss: 4.518\n",
      "\n",
      "Batch: [15] Loss: 0.323, Total loss: 4.841\n",
      "\n",
      "Batch: [16] Loss: 0.322, Total loss: 5.163\n",
      "\n",
      "Batch: [17] Loss: 0.321, Total loss: 5.484\n",
      "\n",
      "Batch: [18] Loss: 0.323, Total loss: 5.807\n",
      "\n",
      "Batch: [19] Loss: 0.322, Total loss: 6.129\n",
      "\n",
      "Batch: [20] Loss: 0.323, Total loss: 6.451\n",
      "\n",
      "Batch: [21] Loss: 0.323, Total loss: 6.774\n",
      "Epoch: [8/10]\n",
      "Epoch: [8/10] loss: 0.751loss: 6.758\n",
      "\n",
      "Batch: [1] Loss: 0.321, Total loss: 0.321\n",
      "\n",
      "Batch: [2] Loss: 0.321, Total loss: 0.642\n",
      "\n",
      "Batch: [3] Loss: 0.323, Total loss: 0.965\n",
      "\n",
      "Batch: [4] Loss: 0.322, Total loss: 1.287\n",
      "\n",
      "Batch: [5] Loss: 0.320, Total loss: 1.607\n",
      "\n",
      "Batch: [6] Loss: 0.322, Total loss: 1.929\n",
      "\n",
      "Batch: [7] Loss: 0.326, Total loss: 2.255\n",
      "\n",
      "Batch: [8] Loss: 0.319, Total loss: 2.574\n",
      "\n",
      "Batch: [9] Loss: 0.322, Total loss: 2.896\n",
      "\n",
      "Batch: [10] Loss: 0.323, Total loss: 3.219\n",
      "\n",
      "Batch: [11] Loss: 0.320, Total loss: 3.539\n",
      "\n",
      "Batch: [12] Loss: 0.322, Total loss: 3.861\n",
      "\n",
      "Batch: [13] Loss: 0.323, Total loss: 4.184\n",
      "\n",
      "Batch: [14] Loss: 0.323, Total loss: 4.507\n",
      "\n",
      "Batch: [15] Loss: 0.324, Total loss: 4.831\n",
      "\n",
      "Batch: [16] Loss: 0.322, Total loss: 5.153\n",
      "\n",
      "Batch: [17] Loss: 0.323, Total loss: 5.475\n",
      "\n",
      "Batch: [18] Loss: 0.323, Total loss: 5.798\n",
      "\n",
      "Batch: [19] Loss: 0.321, Total loss: 6.119\n",
      "\n",
      "Batch: [20] Loss: 0.322, Total loss: 6.441\n",
      "\n",
      "Batch: [21] Loss: 0.321, Total loss: 6.761\n",
      "Saving model...\n",
      "Model saved at model_23_06_06_1059\n",
      "Epoch: [9/10]\n",
      "Epoch: [9/10] loss: 0.750loss: 6.754\n",
      "\n",
      "Batch: [1] Loss: 0.320, Total loss: 0.320\n",
      "\n",
      "Batch: [2] Loss: 0.324, Total loss: 0.644\n",
      "\n",
      "Batch: [3] Loss: 0.324, Total loss: 0.968\n",
      "\n",
      "Batch: [4] Loss: 0.323, Total loss: 1.291\n",
      "\n",
      "Batch: [5] Loss: 0.321, Total loss: 1.613\n",
      "\n",
      "Batch: [6] Loss: 0.322, Total loss: 1.935\n",
      "\n",
      "Batch: [7] Loss: 0.325, Total loss: 2.260\n",
      "\n",
      "Batch: [8] Loss: 0.321, Total loss: 2.580\n",
      "\n",
      "Batch: [9] Loss: 0.321, Total loss: 2.902\n",
      "\n",
      "Batch: [10] Loss: 0.322, Total loss: 3.224\n",
      "\n",
      "Batch: [11] Loss: 0.323, Total loss: 3.547\n",
      "\n",
      "Batch: [12] Loss: 0.324, Total loss: 3.870\n",
      "\n",
      "Batch: [13] Loss: 0.322, Total loss: 4.192\n",
      "\n",
      "Batch: [14] Loss: 0.318, Total loss: 4.510\n",
      "\n",
      "Batch: [15] Loss: 0.322, Total loss: 4.832\n",
      "\n",
      "Batch: [16] Loss: 0.322, Total loss: 5.154\n",
      "\n",
      "Batch: [17] Loss: 0.322, Total loss: 5.477\n",
      "\n",
      "Batch: [18] Loss: 0.322, Total loss: 5.798\n",
      "\n",
      "Batch: [19] Loss: 0.319, Total loss: 6.118\n",
      "\n",
      "Batch: [20] Loss: 0.320, Total loss: 6.438\n",
      "\n",
      "Batch: [21] Loss: 0.322, Total loss: 6.760\n",
      "Saving model...\n",
      "Model saved at model_23_06_06_1059\n",
      "Epoch: [10/10]\n",
      "Epoch: [10/10] loss: 0.751oss: 6.758\n",
      "\n",
      "Batch: [1] Loss: 0.322, Total loss: 0.322\n",
      "\n",
      "Batch: [2] Loss: 0.321, Total loss: 0.643\n",
      "\n",
      "Batch: [3] Loss: 0.324, Total loss: 0.966\n",
      "\n",
      "Batch: [4] Loss: 0.322, Total loss: 1.289\n",
      "\n",
      "Batch: [5] Loss: 0.319, Total loss: 1.608\n",
      "\n",
      "Batch: [6] Loss: 0.319, Total loss: 1.927\n",
      "\n",
      "Batch: [7] Loss: 0.322, Total loss: 2.249\n",
      "\n",
      "Batch: [8] Loss: 0.321, Total loss: 2.570\n",
      "\n",
      "Batch: [9] Loss: 0.319, Total loss: 2.889\n",
      "\n",
      "Batch: [10] Loss: 0.324, Total loss: 3.212\n",
      "\n",
      "Batch: [11] Loss: 0.322, Total loss: 3.535\n",
      "\n",
      "Batch: [12] Loss: 0.319, Total loss: 3.853\n",
      "\n",
      "Batch: [13] Loss: 0.323, Total loss: 4.176\n",
      "\n",
      "Batch: [14] Loss: 0.319, Total loss: 4.495\n",
      "\n",
      "Batch: [15] Loss: 0.319, Total loss: 4.814\n",
      "\n",
      "Batch: [16] Loss: 0.321, Total loss: 5.135\n",
      "\n",
      "Batch: [17] Loss: 0.323, Total loss: 5.458\n",
      "\n",
      "Batch: [18] Loss: 0.320, Total loss: 5.779\n",
      "\n",
      "Batch: [19] Loss: 0.324, Total loss: 6.103\n",
      "\n",
      "Batch: [20] Loss: 0.322, Total loss: 6.425\n",
      "\n",
      "Batch: [21] Loss: 0.321, Total loss: 6.746\n",
      "Saving model...\n",
      "Model saved at model_23_06_06_1059\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "torchAgent = torchAgent(Model(), nn.MSELoss(), epoch=10, verbose=2)\n",
    "torchAgent.add_optimizer(optim.SGD, lr=0.001, momentum=0.9)\n",
    "torchAgent.add_scheduler(optim.lr_scheduler.StepLR, step_size=5, gamma=0.1)\n",
    "torchAgent.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ExtractMfcc(audio_file): \n",
    "    #Function that extracts the Mfcc with librosa\n",
    "    signal, sr = soundfile.read(audio_file)\n",
    "    mfcc = librosa.feature.mfcc(y = signal, sr=sr, n_mfcc=40, hop_length=512, n_fft=1024, window='hamming')\n",
    "    return mfcc[:,:2000]\n",
    "\n",
    "def DisplayMfcc(mfccs):\n",
    "     #Function that displays the Mfcc with librosa\n",
    "    plt.figure(figsize=(25, 10))\n",
    "    librosa.display.specshow(mfccs, \n",
    "                         x_axis=\"time\", \n",
    "                         sr=sr)\n",
    "    plt.colorbar(format=\"%+2.f\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/odysseaslazaridis/Documents/GroupProject/new_babyslack'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor =  torch.tensor(mix_audio, dtype=torch.float32)\n",
    "output_tensor = torch.tensor(guitar_audio, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 100, 700])"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_function_to_list(input_list, func):\n",
    "    return [func(item) for item in input_list]\n",
    "\n",
    "guitar_audio = apply_function_to_list(guitar_path,ExtractMfcc) #create a list of MFCC for guitar\n",
    "mix_audio = apply_function_to_list(mix_path,ExtractMfcc)  #create a list of MFCC for the mix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_signal = librosa.feature.inverse.mfcc_to_audio(mix_audio[0], hop_length=512, n_fft=1024, window='hamming')\n",
    "sf.write('/Users/odysseaslazaridis/Documents/GroupProject/new_babyslack/yay.wav', reconstructed_signal, sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Module.parameters() missing 1 required positional argument: 'self'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[170], line 9\u001b[0m\n\u001b[1;32m      5\u001b[0m target \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrandn(\u001b[39m100\u001b[39m, L)\n\u001b[1;32m      7\u001b[0m torch\u001b[39m.\u001b[39mseed \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m----> 9\u001b[0m optimizer \u001b[39m=\u001b[39m optim\u001b[39m.\u001b[39mLBFGS(CNN\u001b[39m.\u001b[39;49mparameters(), max_iter\u001b[39m=\u001b[39m\u001b[39m6000\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mclosure\u001b[39m():\n\u001b[1;32m     12\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n",
      "\u001b[0;31mTypeError\u001b[0m: Module.parameters() missing 1 required positional argument: 'self'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
